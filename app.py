"""
í¬ë„ ì¬ë°° RAG API - Gradio UI
Railway ë°°í¬ìš©
"""

import gradio as gr
import chromadb
from sentence_transformers import SentenceTransformer
import requests
import os
from datetime import datetime

# ====================
# í™˜ê²½ ë³€ìˆ˜
# ====================

CHROMADB_PATH = os.getenv("CHROMADB_PATH", "./chromadb_unified")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-c8b88a32e75a43ac8a62ce79213696c6")
DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"

# ====================
# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
# ====================

print("â³ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

try:
    # ì„ë² ë”© ëª¨ë¸
    embedding_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
    
    # ChromaDB
    chroma_client = chromadb.PersistentClient(path=CHROMADB_PATH)
    pdf_collection = chroma_client.get_collection("pdf_papers")
    band_collection = chroma_client.get_collection("band_qna")
    youtube_collection = chroma_client.get_collection("youtube_transcripts")
    
    total_docs = pdf_collection.count() + band_collection.count() + youtube_collection.count()
    
    print(f"âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ: {total_docs:,}ê°œ ë¬¸ì„œ")
    SYSTEM_READY = True
    
except Exception as e:
    print(f"âš ï¸ RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    print("âš ï¸ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    SYSTEM_READY = False

# ====================
# ê²€ìƒ‰ í•¨ìˆ˜
# ====================

def search_knowledge(query, n_results=5):
    """ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰"""
    
    if not SYSTEM_READY:
        return [{
            "source_type": "demo",
            "document": "ë°ëª¨ ëª¨ë“œì…ë‹ˆë‹¤. ChromaDBë¥¼ ì—…ë¡œë“œí•˜ë©´ ì‹¤ì œ ë‹µë³€ì´ ì œê³µë©ë‹ˆë‹¤.",
            "distance": 0.0
        }]
    
    try:
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = embedding_model.encode(query).tolist()
        
        # 3ê°œ ì»¬ë ‰ì…˜ ê²€ìƒ‰
        pdf_results = pdf_collection.query(query_embeddings=[query_embedding], n_results=n_results)
        band_results = band_collection.query(query_embeddings=[query_embedding], n_results=n_results)
        youtube_results = youtube_collection.query(query_embeddings=[query_embedding], n_results=n_results)
        
        # ê²°ê³¼ í†µí•©
        all_results = []
        
        for i in range(min(n_results, len(pdf_results['ids'][0]))):
            all_results.append({
                "source_type": "pdf",
                "document": pdf_results['documents'][0][i],
                "distance": pdf_results['distances'][0][i]
            })
        
        for i in range(min(n_results, len(band_results['ids'][0]))):
            all_results.append({
                "source_type": "band",
                "document": band_results['documents'][0][i],
                "distance": band_results['distances'][0][i]
            })
        
        for i in range(min(n_results, len(youtube_results['ids'][0]))):
            all_results.append({
                "source_type": "youtube",
                "document": youtube_results['documents'][0][i],
                "distance": youtube_results['distances'][0][i]
            })
        
        # ê±°ë¦¬ìˆœ ì •ë ¬
        all_results.sort(key=lambda x: x['distance'])
        
        return all_results[:5]
    
    except Exception as e:
        print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

# ====================
# LLM ë‹µë³€ ìƒì„±
# ====================

def generate_answer(query, search_results):
    """DeepSeekìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "**ê²€ìƒ‰ëœ ìë£Œ:**\n\n"
    
    for i, result in enumerate(search_results[:3], 1):
        source_label = {
            "pdf": "ğŸ“„ ë…¼ë¬¸",
            "band": "ğŸ’¬ ë°´ë“œ Q&A",
            "youtube": "ğŸ¥ ìœ íŠœë¸Œ"
        }.get(result['source_type'], "ğŸ“š")
        
        context += f"[{source_label} {i}]\n{result['document'][:300]}...\n\n"
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """ë‹¹ì‹ ì€ í¬ë„ ì¬ë°° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
1. ê²€ìƒ‰ëœ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
2. êµ¬ì¡°í™”ëœ í˜•ì‹ (ìƒí™©ë¶„ì„ â†’ ì¡°ì¹˜ â†’ ê·¼ê±°)
3. ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì§€ì¹¨
4. ê° ì„¹ì…˜ 3-5ì¤„ë¡œ ê°„ê²°í•˜ê²Œ"""

    user_prompt = f"""**ì§ˆë¬¸:** {query}

{context}

ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ í¬ë„ ì¬ë°° ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
            },
            json={
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 1500
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            return f"âš ï¸ API ì˜¤ë¥˜ (ì½”ë“œ: {response.status_code})"
    
    except Exception as e:
        return f"âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)[:100]}"

# ====================
# Gradio ì¸í„°í˜ì´ìŠ¤
# ====================

def chat_interface(message, history):
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    
    if not message.strip():
        return history, ""
    
    # ê²€ìƒ‰
    search_results = search_knowledge(message, n_results=5)
    
    # ë‹µë³€ ìƒì„±
    answer = generate_answer(message, search_results)
    
    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    history.append([message, answer])
    
    return history, ""

# ====================
# Gradio UI
# ====================

with gr.Blocks(
    theme=gr.themes.Soft(),
    title="í¬ë„ ì¬ë°° AI ì „ë¬¸ê°€",
    css="""
    .gradio-container {
        max-width: 900px !important;
        margin: auto !important;
    }
    """
) as demo:
    
    gr.Markdown("""
    # ğŸ‡ í¬ë„ ì¬ë°° AI ì „ë¬¸ê°€
    
    **17,226ê°œ ì „ë¬¸ ë¬¸ì„œ ê¸°ë°˜ AI ì»¨ì„¤íŒ…**
    
    ğŸ“š PDF ë…¼ë¬¸ 7,404ê°œ | ğŸ’¬ í˜„ì¥ Q&A 7,382ê°œ | ğŸ¥ ì „ë¬¸ê°€ ì˜ìƒ 2,440ê°œ
    """)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    status_color = "ğŸŸ¢" if SYSTEM_READY else "ğŸŸ¡"
    status_text = "ì •ìƒ ì‘ë™ ì¤‘" if SYSTEM_READY else "ë°ëª¨ ëª¨ë“œ"
    gr.Markdown(f"{status_color} **ì‹œìŠ¤í…œ ìƒíƒœ:** {status_text}")
    
    with gr.Tab("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°"):
        chatbot = gr.Chatbot(
            label="ëŒ€í™”",
            height=500,
            show_label=True,
            container=True
        )
        
        with gr.Row():
            msg = gr.Textbox(
                label="ì§ˆë¬¸ ì…ë ¥",
                placeholder="ì˜ˆ: ìƒ¤ì¸ë¨¸ìŠ¤ì¼“ ì°©ê³¼ê¸° ê´€ë¦¬ ë°©ë²•ì€?",
                scale=4,
                lines=1
            )
            submit = gr.Button("ì „ì†¡", variant="primary", scale=1)
        
        gr.Examples(
            examples=[
                "ìƒ¤ì¸ë¨¸ìŠ¤ì¼“ ì°©ê³¼ê¸° ê´€ë¦¬ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                "í¬ë„ íƒ„ì €ë³‘ ì˜ˆë°©ë²•ì€?",
                "6ì›” í¬ë„ë‚˜ë¬´ ê´€ë¦¬ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
                "ê³ ì˜¨ ë‹¤ìŠµí•  ë•Œ ì£¼ì˜ì‚¬í•­ì€?"
            ],
            inputs=msg,
            label="ì˜ˆì‹œ ì§ˆë¬¸"
        )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        submit.click(
            fn=chat_interface,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )
        
        msg.submit(
            fn=chat_interface,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )
    
    with gr.Tab("â„¹ï¸ ì •ë³´"):
        gr.Markdown(f"""
        ## ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´
        
        - **ìƒíƒœ**: {status_text}
        - **ë¬¸ì„œ ìˆ˜**: 17,226ê°œ
        - **AI ëª¨ë¸**: DeepSeek-V3
        - **ì„ë² ë”©**: Multilingual-MPNet
        
        ## ğŸ’¡ ì‚¬ìš© íŒ
        
        ### ì§ˆë¬¸ ì˜í•˜ëŠ” ë°©ë²•
        
        **ì¢‹ì€ ì§ˆë¬¸ ì˜ˆì‹œ:**
        - âœ… "ìƒ¤ì¸ë¨¸ìŠ¤ì¼“ ì°©ê³¼ê¸°ì— íƒ„ì €ë³‘ì´ ë³´ì´ëŠ”ë° ì–´ë–»ê²Œ ì¹˜ë£Œí•˜ë‚˜ìš”?"
        - âœ… "6ì›” ì¤‘ìˆœ í¬ë„ë‚˜ë¬´ ê´€ë¦¬ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"
        - âœ… "ê³ ì˜¨ë‹¤ìŠµí•œ ë‚ ì”¨ì— ë…¸ê· ë³‘ ì˜ˆë°©ë²•ì€?"
        
        **í”¼í•´ì•¼ í•  ì§ˆë¬¸:**
        - âŒ "í¬ë„"
        - âŒ "ë³‘"
        - âŒ "ì–´ë–»ê²Œ í•´ìš”?"
        
        ### íŒ
        1. **êµ¬ì²´ì ìœ¼ë¡œ** ì§ˆë¬¸í•˜ì„¸ìš” (í’ˆì¢…, ì‹œê¸°, ì¦ìƒ)
        2. **ìƒí™© ì„¤ëª…**ì„ í¬í•¨í•˜ì„¸ìš”
        3. **ì¶”ê°€ ì§ˆë¬¸**ë„ ììœ ë¡­ê²Œ!
        
        ## ğŸ“ ë¬¸ì˜
        
        ë¬¸ì œê°€ ìˆê±°ë‚˜ ê°œì„  ì‚¬í•­ì´ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”!
        """)
    
    with gr.Tab("ğŸ“ˆ í†µê³„"):
        gr.Markdown("""
        ## ğŸ“Š ì´ìš© í†µê³„
        
        *(ì¶”í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •)*
        
        - ì´ ì§ˆë¬¸ ìˆ˜: -
        - í‰ê·  ì‘ë‹µ ì‹œê°„: -
        - ë§Œì¡±ë„: -
        """)

# ====================
# ì„œë²„ ì‹¤í–‰
# ====================

if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",  # ì™¸ë¶€ ì ‘ì† í—ˆìš©
        server_port=int(os.getenv("PORT", 7860)),  # Railway í¬íŠ¸
        share=False  # Railwayì—ì„œëŠ” share ë¶ˆí•„ìš”
    )
